#!/usr/bin/perl 
#
# count the number of downloads for any file
#

use strict;
use pg2lib;
use Getopt::Long;
use POSIX qw(strftime);

my @yesterday    = localtime (time () - 24 * 60 * 60);
my $date         = strftime ("%Y-%m-%d", @yesterday);
my $session_robot_threshold = 1000; # more than X downloads make session a robot
my $session_timeout = 30 * 60; # in seconds

GetOptions (  "date|d=s"       => \$date,
	   );

die ("Invalid date") unless $date =~ m/\d{4}-\d\d-\d\d/;

my %ip2session;  # session{ip} = session_id
my %sessions;    # hash of hashes sessions{session}{book} = hits
my %books;       # book{downloads}
my %filetypes;   # filetype{downloads}
my $next_id = 0;
my $cnt_robots = 0;

my %bots; # count known bot hits

my (@aa, @ab, @aa_ft);   # temps

my $dbh = pg2lib::connect ();

sub also_downloaded {
    my @res = $dbh->selectrow_array ("SELECT nextval('scores.also_downloads_id_seq')");
    # array of books downloaded from same ip
    foreach my $book (@_) {
        push (@ab, [$res[0], $book]);
    }
}

# push filename, fk_books into a 1-dimensional array
my $res = $dbh->selectcol_arrayref 
    ("SELECT filename, fk_books FROM files WHERE fk_books IS NOT NULL AND diskstatus = 0", 
     {Columns=>[1,2]});
# build hash from array so $file2book{'etext91/alice30.txt'} => 11
#                          $file2book{'1/2/3/4/12345/12345.txt'} => 12345
my %file2book = @$res; 

# add symlinks: files/12345/ symlinks to dirs/1/2/3/4/12345/

for my $fn (keys %file2book) {
    my $ebook_no = $file2book{$fn};
    if ($fn =~ s!\.utf8$!!) { # html.utf8 and txt.utf8 as saved in database
        $file2book{$fn} = $ebook_no;
    }
    if ($fn =~ s!^([\d/]+/)!!) {
        $file2book{"files/$ebook_no/$fn"} = $ebook_no;
    }
}

my $last_time;

while (<>) {
    my ($ip, $time, $file);
    chomp;

    if (m!\+http://([^)"; ]+)!) { # robot signature like +http://www.google.com/bot.html
	$bots{$1}++;
	next;
    }

    if (m!^(\S+).*?\[(\d+)/\w+/\d+:(\d+):(\d+):(\d+).*?\"GET (?:http://[^/]*)?/?(.*) HTTP/\d\.\d\" 20[06] .*$!) {
        $ip = $1;
        $time = 86400 * $2 + 3600 * $3 + 60 * $4 + $5;
        $file = $6;
    } elsif (m!^\w+\s+\w+\s+(\d+)\s+(\d+):(\d+):(\d+)\s+\d+\s+\d+\s+(\d+\.\d+\.\d+\.\d+)\s+\d+\s+/public/ftp/pub/docs/books/gutenberg/(.*)\s+[ab]\s+_\s+o!) {
        $time = 86400 * $1 + 3600 * $2 + 60 * $3 + $4;
        $ip = $5;
        $file = $6;
    } else {
        next;
    }

    if (!exists $ip2session{$ip}) {
        # new ip
        $ip2session{$ip}{'id'} = $next_id++;
    } else {
        my $last = $ip2session{$ip}{'last'};
        # print ("timewarp! $_\n") if ($last > $time + $session_timeout);
        if (($last + $session_timeout < $time) || ($last > $time + $session_timeout)) {
            # ip with expired session
            # a session on an ip expires if there is no activity for timeout seconds
            # beware! time may flow backwards in log files because the timestamp
            # is when the transfer begins and the log line gets written when the
            # transfer is done.
            # beware! time wraps because we get fed both www and ftp logs 
            $ip2session{$ip}{'id'} = $next_id++;
        }
    }
    $ip2session{$ip}{'last'} = $time;
    my $session = $ip2session{$ip}{'id'};

    $file =~ s!\?.*$!!;   # cut arguments from http request

    $file =~ s!^gutenberg/!!;
    $file =~ s!^cdproject/cd/!!;
    $file =~ s!^public/ftp/!!;
    $file =~ s!^pub/docs/books/gutenberg/!dirs/!;

    # next unless $file =~ m!^files/|^dirs/|^cache/!;

    $file =~ s!^dirs/!!;
    $file =~ s!%20! !g;

    # remember all book files (not ebook no. because we still need filetype info)
    if (exists $file2book{$file}) {
        $sessions{$session}{$file}++;
    }
}

while (my ($session, $hfiles) = each %sessions) {

    # for each session

    my %hfiletypes;
    my ($book, $ext);

    foreach my $file (keys %$hfiles) {
	$book = $file2book {$file};
	$ext = $file;
	$ext =~ s!^(.*?)\.(.*)$!$2!;
	$ext = lc ($ext);

        if ($file =~ m!^cache/epub!) {
            $ext = 'html.gen' if ($ext eq 'html');
            $ext = 'txt.utf8' if ($ext eq 'txt');
        }

	$hfiletypes{$book}{$ext}++;
    }

    my $downloads = scalar (keys %hfiletypes);

    # too active sessions are probably bots, ignore them
    if ($downloads <= $session_robot_threshold) {
	while (my ($book, $hft) = each %hfiletypes) {
            # multiple hits from same ip count as one download
            # especially important for mp3s
            $books{$book}++;
	    foreach my $filetype (keys %$hft) {
		$filetypes{$filetype}++;
	    }
	}
        if ($downloads > 1 && $downloads < 10) {
            # collect data for 'also dowloaded' function
            also_downloaded (keys %hfiletypes);
        }
    } else {
        $cnt_robots++;
    }
}

# fix filetypes

my %ft_aliases = qw'htm html html.utf8 html jpeg jpg jpe jpg tif tiff midi mid plucker.pdb plucker qioo.jar qioo';

foreach my $filetype (sort keys %filetypes) {
    if ($filetype =~ m/iso\.[a-z]+$/) {
	$filetypes{'iso'} += $filetypes{$filetype};
	delete $filetypes{$filetype};
    }
    if ($filetype =~ m/part\d+\.rar$/) {
	$filetypes{'rar'} += $filetypes{$filetype};
	delete $filetypes{$filetype};
    }
    if ($filetype =~ m/([a-z]+)\.20[0-9]{6}$/) {
	$filetypes{$1} += $filetypes{$filetype};
	delete $filetypes{$filetype};
    }
}

foreach my $ft (keys %ft_aliases) {
    $filetypes{$ft_aliases{$ft}} += $filetypes{$ft};
    delete $filetypes{$ft};
}

delete $filetypes{'zip'};
delete $filetypes{'rar'};
delete $filetypes{'clb'};
delete $filetypes{'pgw'};
delete $filetypes{'eng'};
delete $filetypes{''};

### make scores.books_downloads

$dbh->do ("DELETE FROM scores.book_downloads WHERE date < current_date - interval '30 days'");
$dbh->do ("DELETE FROM scores.book_downloads WHERE date = '$date'");
$dbh->commit ();

my $ins = $dbh->prepare 
  ("INSERT INTO scores.book_downloads (date, fk_books, downloads) VALUES ('$date', ?, ?)");

while (my ($book, $downloads) = each %books) {
    $ins->execute ($book, $downloads);
    $dbh->commit ();
    # print "$book $downloads\n";
}

$dbh->commit ();

$dbh->do ("UPDATE books SET downloads = 0");
$dbh->do ("UPDATE books SET downloads = d FROM 
  (SELECT fk_books, sum (downloads) as d FROM scores.book_downloads GROUP BY fk_books) as foo 
WHERE foo.fk_books = books.pk");

$dbh->commit ();


### make scores.filetype_downloads

$dbh->do ("DELETE FROM scores.filetype_downloads WHERE date < current_date - interval '30 days'");
$dbh->do ("DELETE FROM scores.filetype_downloads WHERE date = '$date'");
$dbh->commit ();

my $ins = $dbh->prepare 
  ("INSERT INTO scores.filetype_downloads (date, fk_filetypes, downloads) VALUES ('$date', ?, ?)");

while (my ($filetype, $downloads) = each %filetypes) {
    # do this one at a time, will insert only filetypes we know, return error on others
    $ins->execute ($filetype, $downloads);
    $dbh->commit ();
}

### also downloaded

$dbh->do ("DELETE FROM scores.also_downloads WHERE date < current_date - interval '30 days'");
$dbh->do ("DELETE FROM scores.also_downloads WHERE date = '$date'");
$dbh->commit ();

$ins = $dbh->prepare 
  ("INSERT INTO scores.also_downloads (id, fk_books, date) VALUES (?, ?, '$date')");

my @tuple_status;

$ins->execute_for_fetch (sub { shift @ab }, \@tuple_status);

$dbh->commit ();

### make scores.author_downloads

$dbh->do ("DELETE FROM scores.author_downloads WHERE date < current_date - interval '30 days'");
$dbh->do ("DELETE FROM scores.author_downloads WHERE date = '$date'");
$dbh->commit ();

$dbh->do ("INSERT INTO scores.author_downloads 
SELECT date, mn_books_authors.fk_authors as fk_authors, sum (downloads) as downloads
FROM
  scores.book_downloads, mn_books_authors
WHERE
  scores.book_downloads.fk_books = mn_books_authors.fk_books and
  mn_books_authors.fk_authors not in (49, 116, 216) and
  date = '$date'
GROUP BY
  date, mn_books_authors.fk_authors");

$dbh->commit ();

$dbh->do ("UPDATE authors SET downloads = 0");
$dbh->do ("UPDATE authors SET downloads = d FROM 
  (SELECT fk_authors, sum (downloads) as d 
   FROM scores.author_downloads 
   GROUP BY fk_authors) as foo 
WHERE foo.fk_authors = authors.pk");

$dbh->commit ();

$dbh->do ("UPDATE authors SET release_date = '1970-01-01'");
$dbh->do ("UPDATE authors SET release_date = d FROM
  (SELECT fk_authors, max (release_date) as d
   FROM books, mn_books_authors 
   WHERE books.pk = mn_books_authors.fk_books 
   GROUP BY fk_authors) as foo
WHERE foo.fk_authors = authors.pk");

$dbh->commit ();


### make scores.subject_downloads

$dbh->do ("DELETE FROM scores.subject_downloads WHERE date < current_date - interval '30 days'");
$dbh->do ("DELETE FROM scores.subject_downloads WHERE date = '$date'");
$dbh->commit ();

$dbh->do ("INSERT INTO scores.subject_downloads 
SELECT date, mn_books_subjects.fk_subjects as fk_subjects, sum (downloads) as downloads
FROM
  scores.book_downloads, mn_books_subjects
WHERE
  scores.book_downloads.fk_books = mn_books_subjects.fk_books and
  date = '$date'
GROUP BY
  date, mn_books_subjects.fk_subjects");

$dbh->commit ();

$dbh->do ("UPDATE subjects SET downloads = 0");
$dbh->do ("UPDATE subjects SET downloads = d FROM 
  (SELECT fk_subjects, sum (downloads) as d 
   FROM scores.subject_downloads 
   GROUP BY fk_subjects) as foo 
WHERE foo.fk_subjects = subjects.pk");

$dbh->commit ();

$dbh->do ("UPDATE subjects SET release_date = '1970-01-01'");
$dbh->do ("UPDATE subjects SET release_date = d FROM
  (SELECT fk_subjects, max (release_date) as d
   FROM books, mn_books_subjects 
   WHERE books.pk = mn_books_subjects.fk_books 
   GROUP BY fk_subjects) as foo
WHERE foo.fk_subjects = subjects.pk");

$dbh->commit ();


### make scores.bookshelf_downloads

$dbh->do ("DELETE FROM scores.bookshelf_downloads WHERE date < current_date - interval '30 days'");
$dbh->do ("DELETE FROM scores.bookshelf_downloads WHERE date = '$date'");
$dbh->commit ();

$dbh->do ("INSERT INTO scores.bookshelf_downloads 
SELECT date, mn_books_bookshelves.fk_bookshelves as fk_bookshelves, sum (downloads) as downloads
FROM
  scores.book_downloads, mn_books_bookshelves
WHERE
  scores.book_downloads.fk_books = mn_books_bookshelves.fk_books and
  date = '$date'
GROUP BY
  date, mn_books_bookshelves.fk_bookshelves");

$dbh->commit ();

$dbh->do ("UPDATE bookshelves SET downloads = 0");
$dbh->do ("UPDATE bookshelves SET downloads = d FROM 
  (SELECT fk_bookshelves, sum (downloads) as d 
   FROM scores.bookshelf_downloads 
   GROUP BY fk_bookshelves) as foo 
WHERE foo.fk_bookshelves = bookshelves.pk");

$dbh->commit ();

$dbh->do ("UPDATE bookshelves SET release_date = '1970-01-01'");
$dbh->do ("UPDATE bookshelves SET release_date = d FROM
  (SELECT fk_bookshelves, max (release_date) as d
   FROM books, mn_books_bookshelves 
   WHERE books.pk = mn_books_bookshelves.fk_books 
   GROUP BY fk_bookshelves) as foo
WHERE foo.fk_bookshelves = bookshelves.pk");

$dbh->commit ();


### cleanup

$dbh->disconnect ();

my $cnt_ips = keys %ip2session;

print "Done.\n$cnt_ips ips\n$next_id sessions\n$cnt_robots robots.\n\n";

for my $bot (sort { $bots{$a} <=> $bots{$b} } keys %bots) {
    printf ("%6d %s\n", $bots{$bot}, $bot);
}
